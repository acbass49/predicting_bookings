{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb Models\n",
    "\n",
    "Alex Bass (ujb3bu)\n",
    "\n",
    "Kaia Lindberg (pkx2ec)\n",
    "\n",
    "Elina Ribakova (uvg5bn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Final Project Ungraded Assignment\n",
    "At this point in the course, you should be training and evaluating models. Please create a Jupyter Notebook containing a concise summary of your dataset (described in submission instructions).  \n",
    "\n",
    "At a minimum, the file should include a summary containing:\n",
    "\n",
    "- Number of records\n",
    "- Number of columns\n",
    "- Statistical summary of response variable\n",
    "- Statistical summary of potential predictor variables (if there are a large number of predictors, select the top 10)\n",
    "    - Note: Summarize categorical variables with counts and percentages for each level and summarize numerical variables with mean/quantiles/standard deviation.\n",
    "- Include up to five helpful graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "import pyspark.sql.functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for data\n",
    "schema = StructType() \\\n",
    "      .add(\"id\",StringType(),True) \\\n",
    "      .add(\"date_account_created\",StringType(),True) \\\n",
    "      .add(\"timestamp_first_active\",DoubleType(),True) \\\n",
    "      .add(\"date_first_booking\",StringType(),True) \\\n",
    "      .add(\"gender\",StringType(),True) \\\n",
    "      .add(\"age\",DoubleType(),True) \\\n",
    "      .add(\"signup_method\",StringType(),True) \\\n",
    "      .add(\"signup_flow\",IntegerType(),True) \\\n",
    "      .add(\"language\",StringType(),True) \\\n",
    "      .add(\"affiliate_channel\",StringType(),True) \\\n",
    "      .add(\"affiliate_provider\",StringType(),True) \\\n",
    "      .add(\"first_affiliate_tracked\",StringType(),True) \\\n",
    "      .add(\"signup_app\",StringType(),True) \\\n",
    "      .add(\"first_device_type\",StringType(),True) \\\n",
    "      .add(\"first_browser\",StringType(),True) \\\n",
    "      .add(\"country_destination\",StringType(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of columns\n",
    "response_col = \"country_destination\"\n",
    "id_col = \"id\"\n",
    "categorical_cols = [\"gender\", \"signup_method\", \"language\", \n",
    "                    \"affiliate_channel\", \"affiliate_provider\", \"first_affiliate_tracked\",\n",
    "                    \"signup_app\", \"first_device_type\", \"first_browser\"]\n",
    "numeric_cols = [\"timestamp_first_active\", \"age\", \"signup_flow\", ]\n",
    "date_cols = [\"date_account_created\", \"date_first_booking\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in json format\n",
    "df = spark.read.option(\"header\",True).csv(\"train_users_2.csv\", schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for data\n",
    "schema_sessions = StructType() \\\n",
    "      .add(\"user_id\",StringType(),True) \\\n",
    "      .add(\"action\",StringType(),True) \\\n",
    "      .add(\"action_type\",StringType(),True) \\\n",
    "      .add(\"action_detail\",StringType(),True) \\\n",
    "      .add(\"device_type\",StringType(),True) \\\n",
    "      .add(\"secs_elapsed\",DoubleType(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in json format\n",
    "df_sessions = spark.read.option(\"header\",True) \\\n",
    "    .csv(\"sessions.csv\", schema_sessions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate some session data to user level\n",
    "session_agg = df_sessions.groupby('user_id').agg(\n",
    "    fn.sum('secs_elapsed').alias('total_time_elapsed'),\n",
    "    fn.count('action').alias('total_num_actions'),\n",
    "    fn.countDistinct('action').alias('num_unique_actions')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join datasets - use left join to keep as user data\n",
    "# Doing inner join because high % missing session data for train data\n",
    "# But low % missing session data in test data\n",
    "df = df.join(session_agg,df.id ==  session_agg.user_id, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------\n",
      " id_missing                      | 0.0                  \n",
      " date_account_created_missing    | 0.0                  \n",
      " timestamp_first_active_missing  | 0.0                  \n",
      " date_first_booking_missing      | 0.6101876312402628   \n",
      " gender_missing                  | 0.0                  \n",
      " age_missing                     | 0.43687597371807896  \n",
      " signup_method_missing           | 0.0                  \n",
      " signup_flow_missing             | 0.0                  \n",
      " language_missing                | 0.0                  \n",
      " affiliate_channel_missing       | 0.0                  \n",
      " affiliate_provider_missing      | 0.0                  \n",
      " first_affiliate_tracked_missing | 0.004091309354467221 \n",
      " signup_app_missing              | 0.0                  \n",
      " first_device_type_missing       | 0.0                  \n",
      " first_browser_missing           | 0.0                  \n",
      " country_destination_missing     | 0.0                  \n",
      " user_id_missing                 | 0.0                  \n",
      " total_time_elapsed_missing      | 0.01604010025062652  \n",
      " total_num_actions_missing       | 0.0                  \n",
      " num_unique_actions_missing      | 0.0                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Percent missing per column\n",
    "df.agg(*[\n",
    "    (1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing')\n",
    "    for c in df.columns\n",
    "]).show(vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of columns for initial model\n",
    "\n",
    "features = [\"age\", \"gender\", \"signup_method\", \n",
    "            \"language\", \"signup_app\", \n",
    "            \"total_time_elapsed\", \"total_num_actions\", \n",
    "            \"first_device_type\", \"date_account_created\"]\n",
    "\n",
    "df = df.select(features + ['country_destination', 'id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-------+\n",
      "|country_destination|Count|Percent|\n",
      "+-------------------+-----+-------+\n",
      "|                 NL|  247|   0.33|\n",
      "|                 PT|   83|   0.11|\n",
      "|                 AU|  152|   0.21|\n",
      "|                 CA|  440|    0.6|\n",
      "|                 GB|  731|   0.99|\n",
      "|              other| 3655|   4.95|\n",
      "|                 DE|  250|   0.34|\n",
      "|                 ES|  707|   0.96|\n",
      "|                 US|20095|  27.22|\n",
      "|                 FR| 1435|   1.94|\n",
      "|                NDF|45041|  61.02|\n",
      "|                 IT|  979|   1.33|\n",
      "+-------------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary of response variable (count and percentage)\n",
    "\n",
    "df.groupBy(\"country_destination\") \\\n",
    "  .count() \\\n",
    "  .withColumnRenamed('count', 'Count') \\\n",
    "  .withColumn('Percent', fn.round((fn.col('Count') / df.count()) * 100 , 2)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary column (booked place or did not)\n",
    "df = df.withColumn(\n",
    "    'booked',\n",
    "    fn.when((df.country_destination == 'NDF'), 0)\\\n",
    "    .otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|booked|Count|Percent|\n",
      "+------+-----+-------+\n",
      "|     1|28774|  38.98|\n",
      "|     0|45041|  61.02|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary of binary response variable (count and percentage)\n",
    "\n",
    "df.groupBy(\"booked\") \\\n",
    "  .count() \\\n",
    "  .withColumnRenamed('count', 'Count') \\\n",
    "  .withColumn('Percent', fn.round((fn.col('Count') / df.count()) * 100 , 2)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------\n",
      " booked                       | 1                    \n",
      " age_missing                  | 0.2110933481615347   \n",
      " gender_missing               | 0.0                  \n",
      " signup_method_missing        | 0.0                  \n",
      " language_missing             | 0.0                  \n",
      " signup_app_missing           | 0.0                  \n",
      " total_time_elapsed_missing   | 0.012685062904010613 \n",
      " total_num_actions_missing    | 0.0                  \n",
      " first_device_type_missing    | 0.0                  \n",
      " date_account_created_missing | 0.0                  \n",
      " country_destination_missing  | 0.0                  \n",
      " id_missing                   | 0.0                  \n",
      " booked_missing               | 0.0                  \n",
      "-RECORD 1--------------------------------------------\n",
      " booked                       | 0                    \n",
      " age_missing                  | 0.5811149841255745   \n",
      " gender_missing               | 0.0                  \n",
      " signup_method_missing        | 0.0                  \n",
      " language_missing             | 0.0                  \n",
      " signup_app_missing           | 0.0                  \n",
      " total_time_elapsed_missing   | 0.018183432872271976 \n",
      " total_num_actions_missing    | 0.0                  \n",
      " first_device_type_missing    | 0.0                  \n",
      " date_account_created_missing | 0.0                  \n",
      " country_destination_missing  | 0.0                  \n",
      " id_missing                   | 0.0                  \n",
      " booked_missing               | 0.0                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing values by booked by column\n",
    "df.groupby(\"booked\").agg(*[\n",
    "    (1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing')\n",
    "    for c in df.columns\n",
    "]).show(vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace age with nan if outside reasonable range\n",
    "df = df.withColumn(\n",
    "    'age_new', \\\n",
    "    fn.when((df.age > 100) | (df.age < 16), None)\\\n",
    "    .otherwise(df.age)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column indicating whether age is missing or not\n",
    "# Since % missing is higher for those that didn't book\n",
    "# may be a proxy for how effort user has put into updating profile\n",
    "df = df.withColumn(\n",
    "    'age_missing',\n",
    "    fn.when(df.age_new.isNull(), 1)\\\n",
    "    .otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|age_missing|count|\n",
      "+-----------+-----+\n",
      "|          1|32974|\n",
      "|          0|40841|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"age_missing\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'gender',\n",
       " 'signup_method',\n",
       " 'language',\n",
       " 'signup_app',\n",
       " 'total_time_elapsed',\n",
       " 'total_num_actions',\n",
       " 'first_device_type',\n",
       " 'date_account_created',\n",
       " 'country_destination',\n",
       " 'id',\n",
       " 'booked',\n",
       " 'age_new',\n",
       " 'age_missing']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "| first_device_type|count|\n",
      "+------------------+-----+\n",
      "|    Android Tablet|  701|\n",
      "|              iPad| 5238|\n",
      "|            iPhone|10961|\n",
      "|   Windows Desktop|23395|\n",
      "|SmartPhone (Other)|   30|\n",
      "|     Android Phone| 1979|\n",
      "|       Mac Desktop|28029|\n",
      "|     Other/Unknown| 2993|\n",
      "|   Desktop (Other)|  489|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ALEX ADDITION: Time Elapsed Since Account Creation\n",
    "#check device type\n",
    "df.groupby(\"first_device_type\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the `other` categories are a bit small so combining\n",
    "# Create binary column (booked place or did not)\n",
    "df = df.withColumn(\n",
    "    'first_device_type',\n",
    "    fn.when((df.first_device_type == 'Android Tablet'), 'Android Tablet')\\\n",
    "    .when((df.first_device_type == 'iPad'), 'iPad')\\\n",
    "    .when((df.first_device_type == 'iPhone'), 'iPhone')\\\n",
    "    .when((df.first_device_type == 'Windows Desktop'), 'Windows Desktop')\\\n",
    "    .when((df.first_device_type == 'Android Phone'), 'Android Phone')\\\n",
    "    .when((df.first_device_type == 'Mac Desktop'), 'Mac Desktop')\\\n",
    "    .otherwise(\"Other\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|first_device_type|count|\n",
      "+-----------------+-----+\n",
      "|   Android Tablet|  701|\n",
      "|             iPad| 5238|\n",
      "|           iPhone|10961|\n",
      "|  Windows Desktop|23395|\n",
      "|            Other| 3512|\n",
      "|    Android Phone| 1979|\n",
      "|      Mac Desktop|28029|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"first_device_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2014|73815|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(fn.col(\"date_account_created\"),fn.year(fn.col(\"date_account_created\")).alias(\"year\")).groupby(\"year\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like all accounts were created in 2014, so going to use month instead. I thought there would be more variance here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Months Accounts are created in Year 2014')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Also going to create a time elapsed variable to get at longer customers\n",
    "import seaborn as sns\n",
    "temp_data = df.select(fn.col(\"date_account_created\"),fn.month(fn.col(\"date_account_created\")).alias(\"month\")).toPandas()\n",
    "sns.histplot(data=temp_data, x=\"month\")\n",
    "plt.title('Months Accounts are created in Year 2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can treat this as a numeric variable since all months are in 2014.\n",
    "df = df.withColumn(\n",
    "    'date_account_created',\n",
    "    fn.month(fn.col(\"date_account_created\")).alias(\"month\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to rename the variable 'booked' to 'label'\n",
    "df = df.withColumn(\n",
    "    'label',\n",
    "    df['booked']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test\n",
    "seed = 123\n",
    "train, test = df.randomSplit([.7,.3], seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for gender, signup method, language, signup app\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "# Gender\n",
    "gender_idx = StringIndexer(inputCol=\"gender\", outputCol=\"gender_idx\")\n",
    "gender_ohe = OneHotEncoder(inputCol=\"gender_idx\", outputCol=\"gender_vec\")\n",
    "\n",
    "# Signup method\n",
    "signup_method_idx = StringIndexer(inputCol=\"signup_method\", outputCol=\"signup_method_idx\")\n",
    "signup_method_ohe = OneHotEncoder(inputCol=\"signup_method_idx\", outputCol=\"signup_method_vec\")\n",
    "\n",
    "# Language\n",
    "language_idx = StringIndexer(inputCol=\"language\", outputCol=\"language_idx\")\n",
    "language_ohe = OneHotEncoder(inputCol=\"language_idx\", outputCol=\"language_vec\")\n",
    "\n",
    "# Signup app\n",
    "signup_app_idx = StringIndexer(inputCol=\"signup_app\", outputCol=\"signup_app_idx\")\n",
    "signup_app_ohe = OneHotEncoder(inputCol=\"signup_app_idx\", outputCol=\"signup_app_vec\")\n",
    "\n",
    "### Alex Additions ###\n",
    "# First Device Type - Perhaps people browsing on their computer may be more serious about buying vs casual browsing on phone\n",
    "device_idx = StringIndexer(inputCol=\"first_device_type\", outputCol=\"first_device_type_idx\")\n",
    "device_ohe = OneHotEncoder(inputCol=\"first_device_type_idx\", outputCol=\"first_device_type_vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with median\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Age\n",
    "imputer_age = Imputer(\n",
    "    inputCol='age_new', \n",
    "    outputCol='age_new_imputed'\n",
    "    ).setStrategy(\"median\")\n",
    "\n",
    "# Total time elapsed\n",
    "imputer_total_elapsed = Imputer(\n",
    "    inputCol='total_time_elapsed', \n",
    "    outputCol='total_time_elapsed_imputed'\n",
    "    ).setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'gender',\n",
       " 'signup_method',\n",
       " 'language',\n",
       " 'signup_app',\n",
       " 'total_time_elapsed',\n",
       " 'total_num_actions',\n",
       " 'first_device_type',\n",
       " 'date_account_created',\n",
       " 'country_destination',\n",
       " 'id',\n",
       " 'booked',\n",
       " 'age_new',\n",
       " 'age_missing',\n",
       " 'label']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of Age')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of age\n",
    "hists = df.select('age_new').rdd.flatMap(\n",
    "    lambda row: row\n",
    ").histogram(20)\n",
    "\n",
    "data = {\n",
    "    'bins': hists[0][:-1],\n",
    "    'freq': hists[1]\n",
    "}\n",
    "plt.bar(data['bins'], data['freq'], width=5)\n",
    "plt.title('Histogram of Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we use selected features to predict in which country users booked a stay. We use numeric and dummy variables for logistic regression (ridge and lasso), as well as Naive B ....[XXXX]\n",
    "\n",
    "In this section we use numerical features to predict whether a user will book or not with the AirBnB. We are using a simple logistic regression and compute probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the pipeline inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "features = [\"age_new_imputed\", \"age_missing\",\n",
    "            \"gender_vec\", \"signup_method_vec\", \"language_vec\", \"signup_app_vec\",\n",
    "             \"total_time_elapsed_imputed\", \"total_num_actions\", \"first_device_type_vec\", \"date_account_created\"]\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features,\n",
    "                            outputCol=\"fts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all features\n",
    "from pyspark.ml.feature import MaxAbsScaler\n",
    "# Using maxabsscaler because some OHE features are sparse\n",
    "scaler = MaxAbsScaler(inputCol=\"fts\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logistic regression model\n",
    "max_iterations = 10\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=max_iterations,\n",
    "                        featuresCol = 'features',\n",
    "                        labelCol = 'label',\n",
    "                        regParam = 0.3,\n",
    "                        elasticNetParam = 0.8 #penalized logistic regression elasticNetParam = 0.8\n",
    "                        \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[gender_idx, gender_ohe, \n",
    "                           signup_method_idx, signup_method_ohe,\n",
    "                           language_idx, language_ohe,\n",
    "                           signup_app_idx, signup_app_ohe, device_idx, device_ohe,\n",
    "                           imputer_age, imputer_total_elapsed,\n",
    "                           assembler, scaler,\n",
    "                           lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "pipeline_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify data in test set\n",
    "predictions = pipeline_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AUC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"booked\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"booked\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics\n",
    "accuracy = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"f1\"})\n",
    "weightedPrecision = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"weightedRecall\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>booked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.8839755548694519, 0.1160244451305481]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.8632526309882185, 0.13674736901178153]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.8642670848603585, 0.13573291513964147]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.8597332611658636, 0.14026673883413643]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.8543629259232044, 0.1456370740767956]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 probability  prediction  booked\n",
       "0   [0.8839755548694519, 0.1160244451305481]         0.0       0\n",
       "1  [0.8632526309882185, 0.13674736901178153]         0.0       1\n",
       "2  [0.8642670848603585, 0.13573291513964147]         0.0       0\n",
       "3  [0.8597332611658636, 0.14026673883413643]         0.0       0\n",
       "4   [0.8543629259232044, 0.1456370740767956]         0.0       0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficients\n",
    "coef = pipeline_model.stages[-1].coefficients\n",
    "\n",
    "df_pred = predictions.select(\"probability\", \"prediction\", \"booked\").toPandas()\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8839755548694519, 0.1160244451305481]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8632526309882185, 0.13674736901178153]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8642670848603585, 0.13573291513964147]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8597332611658636, 0.14026673883413643]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.8543629259232044, 0.1456370740767956]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features  prediction  \\\n",
       "0      0  (0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...         0.0   \n",
       "1      1  (0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...         0.0   \n",
       "2      0  (0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...         0.0   \n",
       "3      0  (0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...         0.0   \n",
       "4      0  (0.32, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0,...         0.0   \n",
       "\n",
       "                                 probability  \n",
       "0   [0.8839755548694519, 0.1160244451305481]  \n",
       "1  [0.8632526309882185, 0.13674736901178153]  \n",
       "2  [0.8642670848603585, 0.13573291513964147]  \n",
       "3  [0.8597332611658636, 0.14026673883413643]  \n",
       "4   [0.8543629259232044, 0.1456370740767956]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select(\"label\", \"features\", \"prediction\", \"probability\").toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['prob_booked'] = df_pred['probability'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pred['binned_pred'] = pd.qcut(df_pred['prob_booked'], q = 100, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_grpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-31a027d3db64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_grpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Percentile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Percent Booked'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Percent Booked by Model Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_grpd' is not defined"
     ]
    }
   ],
   "source": [
    "df_grpd.plot()\n",
    "plt.xlabel('Predicted Percentile')\n",
    "plt.ylabel('Percent Booked')\n",
    "plt.title('Percent Booked by Model Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", maxIter=100,\n",
    "regParam=0.1, elasticNetParam=0.0, tol=1e-6, fitIntercept=True, standardization=True, solver=\"auto\",\n",
    "weightCol=None, aggregationDepth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Ridge regression model\n",
    "max_iterations = 10\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr_ridge = LogisticRegression(maxIter=max_iterations,\n",
    "                              featuresCol=\"scaledFeatures\", \n",
    "                              labelCol=\"booked\",\n",
    "                              regParam=0.1,\n",
    "                              elasticNetParam=0.0, # Elastic Net Parameter (Ridge = 0, Lasso = 1, Elasticnet inbetween, penalty paramter) \n",
    "                              fitIntercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline_ridge = Pipeline(stages=[gender_idx, gender_ohe, \n",
    "                           signup_method_idx, signup_method_ohe,\n",
    "                           language_idx, language_ohe,\n",
    "                           signup_app_idx, signup_app_ohe,\n",
    "                           imputer_age, imputer_total_elapsed,\n",
    "                           assembler, scaler,\n",
    "                           lr_ridge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "pipeline_ridge = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify data in test set\n",
    "predictions_ridge = pipeline_ridge.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AUC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"booked\")\n",
    "auc_ridge = evaluator.evaluate(predictions)\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"booked\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics\n",
    "accuracy_ridge = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "f1 = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"f1\"})\n",
    "weightedPrecision = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "weightedRecall = evaluatorMulti.evaluate(predictions, {evaluatorMulti.metricName: \"weightedRecall\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>booked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.8839755548694519, 0.1160244451305481]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.8632526309882185, 0.13674736901178153]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.8642670848603585, 0.13573291513964147]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.8597332611658636, 0.14026673883413643]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.8543629259232044, 0.1456370740767956]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 probability  prediction  booked\n",
       "0   [0.8839755548694519, 0.1160244451305481]         0.0       0\n",
       "1  [0.8632526309882185, 0.13674736901178153]         0.0       1\n",
       "2  [0.8642670848603585, 0.13573291513964147]         0.0       0\n",
       "3  [0.8597332611658636, 0.14026673883413643]         0.0       0\n",
       "4   [0.8543629259232044, 0.1456370740767956]         0.0       0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficients\n",
    "coef_ridge = pipeline_ridge.stages[-1].coefficients\n",
    "\n",
    "df_pred = predictions_ridge.select(\"probability\", \"prediction\", \"booked\").toPandas()\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['prob_booked'] = df_pred['probability'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pred['binned_pred'] = pd.qcut(df_pred['prob_booked'], q = 100, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.761051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       AUC\n",
       "0  Logistic  0.500000\n",
       "1     Ridge  0.761051"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Model\" : [\n",
    "        \"Logistic\",\n",
    "        \"Ridge\",\n",
    "        ],\n",
    "    \"AUC\" : [\n",
    "        auc,\n",
    "        auc_ridge]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", maxIter=100,\n",
    "regParam=0.0, elasticNetParam=0.0, tol=1e-6, fitIntercept=True, standardization=True, solver=\"auto\",\n",
    "weightCol=None, aggregationDepth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Lasso regression model\n",
    "max_iterations = 10\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr_ridge = LogisticRegression(maxIter=max_iterations,\n",
    "                              featuresCol=\"scaledFeatures\", \n",
    "                              labelCol=\"booked\",\n",
    "                              regParam=0.0,\n",
    "                              elasticNetParam=1,\n",
    "                              fitIntercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "paramGrid [{Param(parent='LogisticRegression_5eb5731d22f4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0}, {Param(parent='LogisticRegression_5eb5731d22f4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.5}, {Param(parent='LogisticRegression_5eb5731d22f4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.1}, {Param(parent='LogisticRegression_5eb5731d22f4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.01}, {Param(parent='LogisticRegression_5eb5731d22f4', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0}] \n",
      "\n",
      "len(paramGrid): 5\n",
      "------------------------------\n",
      "train time: 1209.661659002304\n",
      "------------------------------\n",
      "elastic net 1 to elastic net 0.01\n",
      "[0.7579579105271874, 0.7579583856346788, 0.7579607975131721, 0.7579566035734275, 0.757957627286034]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Set up the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [1, 0.5, 0.1, 0.01, 0]) \\\n",
    "    .build()\n",
    "\n",
    "print('-'*30)\n",
    "print('paramGrid', paramGrid, '\\n')\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "print('-'*30)\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3,\n",
    "                          seed=1)\n",
    "import time\n",
    "t0 = time.time()\n",
    "cv_model_lr = crossval.fit(df)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)\n",
    "print(\"elastic net 1\", \"to elastic net 0.01\")\n",
    "print(cv_model_lr.avgMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol = 'features',\n",
    "    labelCol = 'label'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "paramGrid [{Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 5, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 5, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 5, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 20, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}, {Param(parent='RandomForestClassifier_9c132f702e08', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_9c132f702e08', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 6}] \n",
      "\n",
      "len(paramGrid): 9\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf = Pipeline(stages=[gender_idx, gender_ohe, \n",
    "                           signup_method_idx, signup_method_ohe,\n",
    "                           language_idx, language_ohe,\n",
    "                           signup_app_idx, signup_app_ohe, device_idx, device_ohe,\n",
    "                           imputer_age, imputer_total_elapsed,\n",
    "                           assembler, scaler,\n",
    "                           rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [3,5,6]) \\\n",
    "    .build()\n",
    "\n",
    "print('-'*30)\n",
    "print('paramGrid', paramGrid, '\\n')\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "print('-'*30)\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline_rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3,\n",
    "                          seed=1)\n",
    "\n",
    "t0 = time.time()\n",
    "cv_model_rf = crossval.fit(df)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)\n",
    "print(cv_model_rf.avgMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(\n",
    "    featuresCol = 'features',\n",
    "    labelCol = 'label'\n",
    ")\n",
    "\n",
    "pipeline_bayes = Pipeline(stages=[gender_idx, gender_ohe, \n",
    "                           signup_method_idx, signup_method_ohe,\n",
    "                           language_idx, language_ohe,\n",
    "                           signup_app_idx, signup_app_ohe, device_idx, device_ohe,\n",
    "                           imputer_age, imputer_total_elapsed,\n",
    "                           assembler, scaler,\n",
    "                           nb])\n",
    "\n",
    "# Set up the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [0, 0.5, 1, 5]) \\\n",
    "    .build()\n",
    "\n",
    "print('-'*30)\n",
    "print('paramGrid', paramGrid, '\\n')\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "print('-'*30)\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline_bayes,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3,\n",
    "                          seed=1)\n",
    "\n",
    "t0 = time.time()\n",
    "cv_model_bayes = crossval.fit(df)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)\n",
    "print(cv_model_bayes.avgMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(\n",
    "    featuresCol = 'features',\n",
    "    labelCol = 'label',\n",
    "    maxIter = 5\n",
    ")\n",
    "\n",
    "pipeline_gbt = Pipeline(stages=[gender_idx, gender_ohe, \n",
    "                           signup_method_idx, signup_method_ohe,\n",
    "                           language_idx, language_ohe,\n",
    "                           signup_app_idx, signup_app_ohe, device_idx, device_ohe,\n",
    "                           imputer_age, imputer_total_elapsed,\n",
    "                           assembler, scaler,\n",
    "                           gbt])\n",
    "\n",
    "# Set up the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [3, 5, 6]) \\ # ER need to change AttributeError: 'GBTClassifier' object has no attribute 'max_depth' need to use 'maxDepth'\n",
    "    .addGrid(gbt.minWeightFractionPerNode, [0, 0.01, 0.1]) \\\n",
    "    .build()\n",
    "\n",
    "print('-'*30)\n",
    "print('paramGrid', paramGrid, '\\n')\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n",
    "print('-'*30)\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline_gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=3,\n",
    "                          seed=1)\n",
    "\n",
    "t0 = time.time()\n",
    "cv_model_gbt = crossval.fit(df)\n",
    "print(\"train time:\", time.time() - t0)\n",
    "print('-'*30)\n",
    "print(cv_model_gbt.avgMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ER to check TypeError: 'int' object is not iterable\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Model\" : [\n",
    "        \"Lasso\",\n",
    "        \"Ridge\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Random Forest\",\n",
    "        \"GBT\"\n",
    "    ],\n",
    "    \"AUC\" : [\n",
    "        cv_model_lr.avgMetrics[0],\n",
    "        cv_model_lr.avgMetrics[max(len(cv_model_lr.avgMetrics))],\n",
    "        max(cv_model_nb.avgMetrics),\n",
    "        max(cv_model_rf.avgMetrics),\n",
    "        max(cv_model_gbt.avgMetrics)\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ER to check TypeError: 'int' object is not iterable\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Model\" : [\n",
    "        \"Logistic\",\n",
    "        \"Ridge\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Random Forest\",\n",
    "        \"GBT\"\n",
    "    ],\n",
    "    \"AUC\" : [\n",
    "        auc,\n",
    "        auc_ridge],\n",
    "        max(cv_model_nb.avgMetrics),\n",
    "        max(cv_model_rf.avgMetrics),\n",
    "        max(cv_model_gbt.avgMetrics)\n",
    "    ]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
